---
title: "Classification 2"
output: html_notebook
---

# Classification 2

```{r}
library(ISLR)
attach(Default)
summary(Default)
```

## Performing KNN classification in R

#### to perfrom KNN classificatino, we use `knn()` in the `class` package.

```{r}
install.packages("class")
library(class)
```
- R will randomily break the nearest neighbors tie.
- enable reproducibility: set a seed before running `knn()`

```{r}
set.seed(1)
```

## knn()requires four inputs:
1) Matrix of feature measurements for training data
2) Matrix of feature measurements for test data
3) Vector of class labels for training data
4) Value for 𝐾, the number of nearest neighbors to use

### Input 1: Matrix of feature measurements for training data
 
- We will use KNN to make predictions about default from student, balance, and income.
- Recall that we have 10,000 observations on four variables: default, student, balance, and income.
- We need to split this dataset into a training dataset and test dataset.
- Let’s use the first 9,000 observations (rows) as our training dataset:
```{r}
train = seq(1,9000)
train.x = cbind(student, balance, income)[train,]
test = seq(9001, 10000)
test.x = cbind(student, balance, income)[test,]
train.y = default[train]
knn.pred = knn(train.x, test.x, train.y, k=1)
summary(knn.pred) #summary
knn.pred #full output
```

## Assessing test accuracy of KNN in predicting default in R

- KNN classification with K=1

```{r}
knn.pred = knn(train.x, test.x, train.y, k=1)
test.y = default[test]
```

#### creating a table 

```{r}
table(knn.pred, test.y)
```

## Assessing test accuracy of KNN in predicting default in R

- Test accuracy rate is just the total number of correct predictions $(y_0 + y_0(hat)) $  Divided by the total number of predictions:

```{r}
# test error rate
(943 + 10) / 1000

# can also use the mean() function
mean(knn.pred == test.y)
```

#### finished with stuff for HW 3

## Simple Logistic Regression
- Simple logistic regression models the probability that 𝑌 belongs to a particular class 𝑗 given a single feature 𝑋 with the logistic function
- see slide 106 in lecture 8, classification, to see the formula 

## stopped at 2:36:25

